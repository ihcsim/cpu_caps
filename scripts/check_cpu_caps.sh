#!/bin/bash

# This script collects the virsh capabilities files from all virt-handler pods in
# the ${KUBEVIRT_NAMESPACE} namespace. It also starts an ephemeral container in
# each virt-handler pod to run a custom version of the virt-handler image (defined
# by the ${VIRT_HANDLER_IMAGE} variable), to collect the same set of virsh
# capabilities files.
#
# We can compare the collected virsh capabilities files to identify differences
# betweeen different versions of virt-handler.
#
# This script requires kubeconfig to be included in $PATH, with permissions to
# run `kubectl [debug|cp|exec]` targeting the ${KUBEVIRT_NAMESPACE} namespace.
#
# When launched, the ehpemeral container executes the built-in node-labeller.sh
# script, writes the output XML files to the container's
# /var/lib/kubevirt-node-labeller, and copies the output from the container to
# your shell.

set -xe

KUBEVIRT_NAMESPACE=${KUBEVIRT_NAMESPACE:-harvester-system}
VIRT_HANDLER_IMAGE=${VIRT_HANDLER_IMAGE:-registry.suse.com/suse/sles/15.7/virt-launcher:1.5.2-150700.3.5.2}
DEBUGGER_TTL_SECONDS=3600

now=$(date "+%Y%m%d-%H%M%S")
src_dir=$(dirname $(readlink -f -- "${BASH_SOURCE[0]}"))
virt_handlers=($(kubectl -n "${KUBEVIRT_NAMESPACE}" get po \
  -lkubevirt.io=virt-handler \
  --no-headers \
  -ojsonpath='{range .items[]}{.metadata.name},{.spec.nodeName}{"\n"}{end}'))

# collect the virsh capabilities .xml files from the hostpath
# /var/lib/kubevirt-node-labeller.
function cpu_caps() {
  for virt_handler in "${virt_handlers[@]}"; do
    local pod_name=$(echo "${virt_handler}" | cut -d',' -f1)
    local node_name=$(echo "${virt_handler}" | cut -d',' -f2)
    kubectl -n "${KUBEVIRT_NAMESPACE}" cp -c virt-handler "${pod_name}":/var/lib/kubevirt-node-labeller ./out-"${now}/${node_name}/current"
  done
}

# start an ephemeral container to collect the virsh capabilities .xml files
# generated by the custom virt-handler. the debugger references the in-container
# /var/lib/kubevirt-node-labeller folder, not the one on the host.
function cpu_caps_custom() {
  for virt_handler in "${virt_handlers[@]}"; do
    local pod_name=$(echo "${virt_handler}" | cut -d',' -f1)
    local node_name=$(echo "${virt_handler}" | cut -d',' -f2)
    local debugger_name=debug-"${now}"
    kubectl -n "${KUBEVIRT_NAMESPACE}" debug \
      --image="${VIRT_HANDLER_IMAGE}" \
      --container "${debugger_name}" \
      --profile=general \
      --custom="${src_dir}"/scc.yaml \
      "${pod_name}" -- /bin/bash -c "set -e; mkdir -p /var/lib/kubevirt-node-labeller; node-labeller.sh; touch /var/lib/kubevirt-node-labeller/.done; sleep ${DEBUGGER_TTL_SECONDS}"

    set +e
    while true; do
      kubectl -n "${KUBEVIRT_NAMESPACE}" exec -c "${debugger_name}" "${pod_name}" -- ls -al /var/lib/kubevirt-node-labeller/.done
      if [ "$?" -eq 0 ]; then
        break
      fi
    done
    set -e

    local image_tag=$(echo "${VIRT_HANDLER_IMAGE}" | cut -d":" -f2)
    kubectl -n "${KUBEVIRT_NAMESPACE}" cp -c "${debugger_name}" "${pod_name}":/var/lib/kubevirt-node-labeller ./out-"${now}/${node_name}/${image_tag}"
  done
}

function tarball() {
  tar -cvf ./out-"${now}".tar.gz ./out-"${now}"
  rm -rf ./out-"${now}"
}

cpu_caps
cpu_caps_custom
tarball
